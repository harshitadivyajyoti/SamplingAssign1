# SamplingAssign1
Under the course **Predictive Analytics Using Statistics**

## üìå Project Overview
This project analyzes the impact of different sampling techniques on the performance of various machine learning models. Using a Credit Card Fraud Detection dataset, the project addresses class imbalance through oversampling, applies five distinct sampling techniques, and evaluates five different predictive models to determine which combination yields the highest accuracy.

## üìÇ Dataset
* **Source:** [Credit Card Fraud Detection Dataset](https://github.com/AnjulaMehto/Sampling_DataSet/tree/main)
* **Characteristics:** The original dataset is highly unbalanced.
* **Preprocessing:** The minority class was oversampled using random oversampling to create a balanced dataset before applying specific sampling techniques.

## ‚öôÔ∏è Methodology

### 1. Data Balancing
The original dataset was heavily skewed (Majority Class: 763, Minority Class: 9). To handle this, **Random Oversampling** was applied to the minority class to match the size of the majority class, resulting in a balanced dataset of **763 instances per class** (Total: 1526 records).

### 2. Sampling Techniques
Five different sampling methods were employed to create training subsets:
1.  **Simple Random Sampling:** Randomly selects samples from the population with equal probability.
2.  **Systematic Sampling:** Selects every $k^{th}$ member from the population after a random start.
3.  **Stratified Sampling:** Divides the population into subgroups (strata) based on the target class and samples from each stratum to maintain proportion.
4.  **Cluster Sampling:** Groups the data into clusters (based on a generated index), randomly selects specific clusters, and includes all members of those clusters.
5.  **Probability Proportional to Size (PPS) Sampling:** Selects samples where the probability of selection is proportional to the size of the target variable.

### 3. Machine Learning Models
Five different classifiers were trained on the samples generated by the techniques above:
* **Logistic Regression**
* **Decision Tree**
* **Random Forest**
* **K-Nearest Neighbors (KNN)**
* **Support Vector Machine (SVM)**

## üìä Results

The following table represents the accuracy score achieved by each model using different sampling techniques on the test set.

| Sampling Technique | Logistic Regression | Decision Tree | Random Forest | KNN | SVM |
| :--- | :---: | :---: | :---: | :---: | :---: |
| **Simple Random** | 0.6749 | 0.5876 | 0.5370 | 0.5023 | 0.5023 |
| **Systematic** | 0.6609 | 0.6229 | 0.5483 | 0.4977 | 0.6322 |
| **Stratified** | 0.6049 | 0.6036 | 0.5783 | 0.5023 | 0.5023 |
| **Cluster** | 0.5803 | 0.5730 | 0.5750 | 0.4977 | 0.4977 |
| **PPS** | **0.6775** | 0.4670 | 0.5543 | 0.4977 | 0.4977 |

### üîç Key Findings
* **Logistic Regression** generally performed the best across most sampling techniques, achieving the highest accuracy of **67.75%** with PPS sampling.
* **PPS (Probability Proportional to Size)** combined with Logistic Regression yielded the highest overall result.
* **SVM** showed significant variance, performing well with Systematic sampling (63.22%) but poorly with others.
* **KNN** consistently showed lower performance (approx 50%) across all sampling methods.

## üìù How to Run
1.  Clone this repository.
2.  Ensure you have `Creditcard_data.csv` in the directory.
3.  Install dependencies: `pip install pandas numpy scikit-learn`
4.  Run the Jupyter Notebook or Python script to reproduce the results.
